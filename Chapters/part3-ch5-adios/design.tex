{\color {red}Where is the library positioned in the I/O stack? What design constraints drove the architecture?}

ADIOS~\cite{ADIOS:Lofstead:ipdps09}...

The basic design decisions for ADIOS have been the following:
\begin{itemize}
\item Simple programming API that does not express I/O strategy, but instead just declares what to output,
\item XML-based external description of output data and selection of I/O
strategy,
\item Multiple transport methods selectable at runtime,
\item Self describing, log-based file format combined with buffered writing for best possible write performance.
\end{itemize}

ADIOS sits on the top of the I/O stack as a user-level I/O library. The write API of ADIOS is designed to be as close to the POSIX I/O calls as possible, but without a fix specification about what happens in a "write" call. Datasets are "opened" and "closed" and variables are "written" to them. In general, write calls only buffer the data content, and in the close call, ADIOS performs burst writes to the file system. However, it depends on the I/O method used in ADIOS, what is done with the data.

The API lets the scientist express I/O in terms of variables in the code as with HDF5 or NetCDF. No byte-level access to the output, nor seeking is possible. An ADIOS dataset consists of typed, multi-dimensional arrays or simple scalars, with global dimensions defined by scalar variables (similar to NetCDF dimensions) or simply by number values. A writing process also has to declare where its array fits in a global array using offsets and local dimensions. 

\subsection{ADIOS-BP file format}
The file format designed for ADIOS, and used by most file-based I/O methods in ADIOS, provides a self-describing data format, a log-based data organization and redundant metadata for resiliency and performance. The log-based data organization affords ADIOS writing each process' output data into a separate chunk of the file concurrently. In contrast with logically contiguous file formats where the data in the memory of the processes has to be reorganized to be stored on disk according to the global, logical organization, this format eliminates i) communication among processes when writing to reorder data and ii) seeking to multiple offsets in the file by a process to write data interleaved with what is written by other processes. Coupled with buffering by the processes, which exploits the best available I/O bandwidth by streaming large, contiguous chunks to disk, the destination format itself avoids bottlenecks that would hamper that performance. The many processes writing to different offsets in a file or to different files even are avoiding each other on a parallel file system to the extent possible. In most cases, each process attempts to write to a single stripe target to avoid the metadata server overhead of spanning storage targets.  The reading performance of this choice was shown to be generally advantageous as well~\cite{ADIOS:Lofstead:hpdc11}.

